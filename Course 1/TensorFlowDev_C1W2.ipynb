{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlowDev_C1W2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiyN665ixesf+vYRQ6sQiV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mosesandrian/TensorFlowDeveloperCourse/blob/main/Course%201/TensorFlowDev_C1W2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htxt_wGDllVf"
      },
      "source": [
        "# **Computer Vision - Fashion MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXWNrOo3orCE"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYbeZ71sljk2"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E57TVB21l9zS"
      },
      "source": [
        "the data would be divided into **training** and **testing** set.\n",
        "\n",
        "a set of data would contain an image (28x28 pixels) with a label prepared (01-10) to identify the corresponding picture. numbers used to decrease bias.\n",
        "\n",
        "> https://ai.google/responsibilities/responsible-ai-practices/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VEhwRibsH74"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_images[42])\n",
        "print(train_labels[42])\n",
        "# print(train_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGlEVbWAs58Q"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SylgAxTkm8bE"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)                     \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8o7t5UpnSR0"
      },
      "source": [
        "* **Flatten** turns 28x28 pixels into simple linear layer\n",
        "* 128 **Dense** neurons provides a hidden layer after 28x28 inputs, to 10 individual outputs\n",
        " * try other numbers for the hidden layer, and figure out what are the effects\n",
        "\n",
        "With higher Dense neurons, it took a much longer time to fit the data, however, it is far more accurate! That doesn't mean it's always a case of 'more is better', you can hit the law of diminishing returns very quickly!\n",
        "\n",
        "There **isn't a significant impact** in adding more Dense layers-- because this is relatively simple data. *For far more complex data (including color images to be classified as flowers that you'll see in the next lesson), extra layers are often necessary.*\n",
        "\n",
        "More epochs = **overfitting**!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak3hrmEGRgUQ"
      },
      "source": [
        "**Relu** effectively means \"If X>0 return X, else return 0\" -- so what it does it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "**Softmax** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0AnUn7CtTB1",
        "outputId": "100a6b45-19f9-4633-ae50-93f482ff2558"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_images,train_labels,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2820 - accuracy: 0.8967\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2714 - accuracy: 0.8986\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2620 - accuracy: 0.9031\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2456 - accuracy: 0.9086\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2363 - accuracy: 0.9115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1404d77c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2PytwiTt9Zu",
        "outputId": "81251919-9f79-4215-a023-f90d4d547dee"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.8809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34057894349098206, 0.8809000253677368]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZTJPQiwviNz"
      },
      "source": [
        "This part evaluates the whole system into a new set of test image and labels. Should provide a better, non-biased accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ_en8avvfBJ",
        "outputId": "820a0014-2308-4fd7-8e87-9d448446f16a"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.3609798e-07 4.9956714e-09 2.2587209e-08 4.0417309e-09 1.2508775e-07\n",
            " 1.8587664e-03 9.7090162e-07 3.9864771e-02 2.6094108e-07 9.5827442e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3IK9mqhvwXa"
      },
      "source": [
        "This shows the classification of Picture 0, that represents a highest probability of label: 9. Or called: an ankle boot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYQEP29MPAZK"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):  # is set up on epoch_end, prevent fluctuations\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback() # to set up callbacks as part of a class of myCallback\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d4iuDPbPEA5"
      },
      "source": [
        "The code above is representing a callback to stop the epoch iteration and fitting to a desired accuracy or loss.\n",
        "\n",
        "Loss is stored into a certain log. *self.model.stop.training = True*, to stop the training\n",
        "\n",
        "We need to call it first before the model.fit and also within the fitting procedure. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKaHFvmRS5X-"
      },
      "source": [
        "# **Exercise 2 - Handwriting Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMF-kQc8TQOl"
      },
      "source": [
        "import tensorflow as tf\n",
        "from os import path, getcwd, chdir\n",
        "\n",
        "# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n",
        "# environment, then grab mnist.npz from the Coursera Jupyter Notebook\n",
        "# and place it inside a local folder and edit the path to that location\n",
        "path = f\"{getcwd()}/../tmp2/mnist.npz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CfcyjeLtBQU"
      },
      "source": [
        "# GRADED FUNCTION: train_mnist\n",
        "def train_mnist():\n",
        "    # Please write your code only where you are indicated.\n",
        "    # please do not remove # model fitting inline comments.\n",
        "\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self,epoch,logs={}):\n",
        "            if(logs.get('acc')>0.99):\n",
        "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "                self.model.stop_training = True\n",
        "    \n",
        "    callbacks = myCallback()\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # YOUR CODE SHOULD START HERE\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "        # YOUR CODE SHOULD END HERE\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # model fitting\n",
        "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
        "              x_train, y_train, epochs = 10, callbacks=[callbacks]\n",
        "              # YOUR CODE SHOULD END HERE\n",
        "    )\n",
        "    # model fitting\n",
        "    return history.epoch, history.history['acc'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}